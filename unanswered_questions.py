# -*- coding: utf-8 -*-
"""Unanswered questions - Em and Dan .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-XtYg7sm4bSqWKMh7rL8TyIr5D7U4hzL

#Import the Data
"""



import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

attorney = pd.read_csv("/content/drive/Shareddrives/Data Fest 2023/data/attorneys.csv")
attTimeEntires = pd.read_csv("/content/drive/Shareddrives/Data Fest 2023/data/attorneytimeentries.csv")
cat = pd.read_csv("/content/drive/Shareddrives/Data Fest 2023/data/categories.csv")
client = pd.read_csv("/content/drive/Shareddrives/Data Fest 2023/data/clients.csv")
questionP = pd.read_csv("/content/drive/Shareddrives/Data Fest 2023/data/questionposts.csv")
questions = pd.read_csv("/content/drive/Shareddrives/Data Fest 2023/data/questions.csv")
statesite = pd.read_csv("/content/drive/Shareddrives/Data Fest 2023/data/statesites.csv")
subcat = pd.read_csv("/content/drive/Shareddrives/Data Fest 2023/data/subcategories.csv")

attorney.head()

attTimeEntires.head()

cat.head()

client.head()

questionP.head()

questions.head()

statesite.head()

subcat.head()

"""#Extract Unanswered Questions


"""

nottaken = questions[questions['TakenOnUtc'].isna()]
#nottaken.shape
#questions.shape
nottaken.shape[0] /questions.shape[0] * 100

"""There were 57228 out of 202879 questions not taken by the attorneys. That is 28.2 percent of the questions."""

#nottaken

grouped = nottaken.groupby(['Category', 'Subcategory'])

grouped.first()

"""#Preprocessing Question Data"""

ques = questions.drop(columns=['Id', 'CategoryUno','SubcategoryUno','AskedByClientUno','AskedOnUtc' ,  'ClosedByAttorneyUno', 'ClosedOnUtc' ])
ques

questionP

#qgroup = questionP.groupby('QuestionUno', group_keys=True).apply(lambda x: x)
qPid = questionP['QuestionUno']
qPid.drop_duplicates()

uniqueques = qPid.drop_duplicates()
uniqueques.index

reducedQ = questionP.iloc[uniqueques.index]
reducedQ

#reducedQ.to_csv('/content/drive/Shareddrives/Data Fest 2023/data/reducedQuestions', index=False)

mergedq = pd.merge(reducedQ, questions, on='QuestionUno')
mergedq = mergedq.drop(columns = ['Id_x', 'StateAbbr_x', 'CreatedUtc','Id_y', 'AskedOnUtc',  'ClosedByAttorneyUno', 'ClosedOnUtc'])

mergedq = mergedq.rename(columns={"StateAbbr_y": "StateAbbr"})
mergedq

#mergedq.to_csv('/content/drive/Shareddrives/Data Fest 2023/data/MergedQuestions.csv', index=False)

"""#Attorney Info"""

attorney

newq = questions.dropna(subset=['ClosedByAttorneyUno'])
newq = newq.rename(columns={"ClosedByAttorneyUno": "AttorneyUno"})
newq

att = pd.merge(attorney, newq, on='AttorneyUno')
att
att.to_csv('/content/drive/Shareddrives/Data Fest 2023/data/attorney_cases.csv', index=False)

#att.to_csv('/content/drive/Shareddrives/Data Fest 2023/data/attorney_cases.csv', index=False)

g1 = att.groupby('AttorneyUno')['Category'].sum()
g1

att['count'] = 1

att

g2 = att.groupby(['AttorneyUno','Category'])['count'].sum()

attcatcount = pd.DataFrame(g2)
attcatcount

#attcatcount.to_csv('/content/drive/Shareddrives/Data Fest 2023/data/attorney_cat_count.csv', index=False)

attcatcount

